{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L'algorithme de descente de gradient "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Le cas d'une fonctionnelle quadratique\n",
    " \n",
    "Tout d'abord, nous appliquons la méthode à une fonctionnelle quadratique :\n",
    "\\begin{align}\\label{quadf}\\tag{1} f(x)=\\dfrac12 x^TA x + b^T x +c,\\qquad \\text{pour } x\\in \\mathbb{R}^ N, \\end{align}\n",
    "avec\n",
    "$A$ une matrice réelle $N\\times N$, symétrique définie positive, $b\\in\\mathbb{R}^N$ et $c\\in \\mathbb{R}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** Calculez le gradient et la matrice Hessienne de $f$.\n",
    "\n",
    "**Question 2.** Que pouvez-vous en déduire sur la nature de $f$ ?\n",
    "\n",
    "**Question 3.** Montrez que $f$ atteint son minimum sur $\\mathbb{R}^N$ en un seul point $x^*$. Donnez une caractérisation de ce point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 L'algorithme de descente de gradient à pas optimal\n",
    "\n",
    "Soit $f$ une fonction convexe et coercive de classe $C^1$ sur $\\mathbb{R}^N$. L'algorithme de descente de gradient à pas optimal est défini comme suit. \n",
    "\n",
    "Soit $x^0\\in \\mathbb{R}^N$ (on essaie de choisir $x^0$ proche de $x^*$, en l'absence d'indication on prend $x^0=0$). \n",
    "\n",
    "Ensuite, pour $k=0,1,2,\\ldots\\ $ jusqu'à convergence, répéter : \n",
    "\n",
    "$$\n",
    "\\left|\n",
    "\\begin{array}{lcl}\n",
    "d^k& \\longleftarrow & -\\nabla f(x^k),\\\\\n",
    "\\alpha_k &\\longleftarrow &\\mathop{argmin}_{t>0} f(x^k + td^k),\\\\ \n",
    "x^{k+1}&\\longleftarrow &x^k+\\alpha_k d^k\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** Proposez un critère d'arrêt pour l'algorithme qui utilise la caractérisation de la question **3**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarque :** En général, on ne sait pas calculer $\\alpha_k$ et en pratique, la deuxième étape est remplacée par une recherche approchée. Cependant, lorsque $f$ est quadratique, le calcul de $\\alpha_k$ est ``facile''. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.** Dans le cas de la fonction quadratique (1), explicitez $d^k$ et $\\alpha_k$ comme fonctions de $A$, $x^k$ et $b$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, nous spécifions $N=2$ et\n",
    "$$ A=\\binom{C\\quad 0}{0\\quad 1},\\quad C\\ge 1,\\quad b=0,\\quad c=0.$$\n",
    "**Question 6.** Quel est l'infimum de $f$ sur $\\mathbb{R}^2$ dans ce cas ? Donner $x^*$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7.** Deux fonctions sont données ci-dessous :\n",
    "- une fonction qui dessine un champ de vecteur donné par une application $F$. À titre d'exemple, elle est appliquée au champ de vecteurs $G(x,y)=(x, 8y)$ dans la boîte $[-8,8]\\times[-2.1,2.1]$.\n",
    "- une fonction qui dessine quelques lignes de niveau d'une fonction $f$. Elle est appliquée à $g(x,y)=\\dfrac{x^2+8x^2}2$ toujours dans la boîte $[-8,8]\\times[-2.1,2.1]$ avec 8 lignes de niveaux $g=0$, $g=4$, $\\dots$, $g=28$.\n",
    "\n",
    "Notez que $G=\\nabla g$. Qu'observez-vous ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def draw_vector_field(F, xmin, xmax, ymin, ymax, N=20):\n",
    "    X = np.linspace(xmin, xmax, N)  # x coordinates of the grid points\n",
    "    Y = np.linspace(ymin, ymax, N)  # y coordinates of the grid points\n",
    "    U, V = F(*np.meshgrid(X, Y))  # vector field\n",
    "    M = np.hypot(U, V)  # compute the norm of (U,V)\n",
    "    M[M == 0] = 1  # avoid division by 0\n",
    "    U /= M  # normalize the u componant\n",
    "    V /= M  # normalize the v componant\n",
    "    return plt.quiver(X, Y, U, V, angles='xy')\n",
    "\n",
    "def level_lines(f, xmin, xmax, ymin, ymax, levels, N=500):\n",
    "    x = np.linspace(xmin, xmax, N)\n",
    "    y = np.linspace(ymin, ymax, N)\n",
    "    z = f(*np.meshgrid(x, y))\n",
    "    level_l = plt.contour(x, y, z, levels=levels)\n",
    "    #plt.clabel(level_l, levels, fmt='%.1f') \n",
    "\n",
    "\n",
    "g = lambda x, y: .5*(x**2 + 8*y**2)\n",
    "G = lambda x, y: np.array([x, 8*y])\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12,6))\n",
    "level_lines(g, -8, 8, -3, 3, np.linspace(0, 28, 8))\n",
    "draw_vector_field(G,  -8, 8, -3, 3, 18)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** Implémentez l'algorithme de descente de gradient à pas optimal. Le point initial doit être $x^0=\\binom1C$.\n",
    "\n",
    "**Question 9.** Sur le même graphique, représentez les itérations, quelques lignes de niveau de $f$ et le champ de vecteur normalisé $\\dfrac {1}{|\\nabla f|}\\nabla f$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10.** Changez la valeur de $C$ de 1 à 32 ($C=1,2,4,8,16,32$). Qu'observez-vous ?\n",
    "\n",
    "**Question 11.** Tracez le nombre d'itérations de la méthode en fonction de $C$. Faites une hypothèse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initialisation\n",
    "make_f = lambda c: lambda x, y=1: .5*(c*x**2 + y**2)\n",
    "make_df = lambda c: lambda x, y : np.array([c*x, y])\n",
    "\n",
    "tab_C=(1,2,4,8,16,32)\n",
    "tab_niter=np.zeros(6)\n",
    "\n",
    "epsilon = 1e-8  #tolérance sur l'erreur\n",
    "\n",
    "for j in range(6):\n",
    "    ## initialisations\n",
    "    C = tab_C[j]\n",
    "    f, df = make_f(C), make_df(C)\n",
    "    x, y = 1., C \n",
    "    X = [np.array([x,y])] # array for the values of $x^k$\n",
    "    F = [f(x,y)] # array for the values of $f(x^k)$\n",
    "    niter =0\n",
    "    \n",
    "    ## Boucle d'optimisation \n",
    "    while(True):\n",
    "        dx,dy = -df(x,y)    # calcule de d^k  \n",
    "        normd = np.hypot(dx,dy)\n",
    "        if normd<epsilon:   # test du critère darrêt\n",
    "            break\n",
    "        alpha = normd**2/(C*dx**2 + dy**2)  # calcul du pas optimal\n",
    "        x, y = x + alpha*dx, y + alpha*dy       # nouvel itéré\n",
    "        niter += 1 \n",
    "        X.append(np.array([x,y]))\n",
    "        F.append(f(x,y))\n",
    "    tab_niter[j]=niter\n",
    "    \n",
    "    ## représentations graphiques         \n",
    "    X = np.array(X)\n",
    "    F = np.array(F)\n",
    "   \n",
    "    plt.figure()\n",
    "    plt.plot(X[:,0],X[:,1],'.',linestyle='-')\n",
    "    level_lines(f, -2.1, 2.1, 0, C, np.linspace(0, .5*C**2, 10))\n",
    "    #draw_vector_field(df, C,  -2.1, 2.1, 0, C, 20)\n",
    "    plt.axis('equal')\n",
    "    plt.title(\"C=\"+str(C))\n",
    "\n",
    "    # plot of the values of f along the iterations.\n",
    "    plt.figure()\n",
    "    plt.semilogy(range(len(F)),F,'.')\n",
    "    plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tab_C,tab_niter,'.',linestyle='dashed')\n",
    "plt.title(\"Nombre d'itérations en fonction de C\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Le cas d'une fonction convexe régulière, line search. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On considère la fonction définie par\n",
    "$$\n",
    "f(x,y):= \\cosh(x) + \\sin^2(x+y),\\qquad \\text{pour }z=(x,y)\\in \\mathbb{R}^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.** Montrerque les minimiseurs de $f$ sont les points de la form $(0,n\\pi)$ pour $n\\in\\mathbb{Z}$.\n",
    "\n",
    "Montrer que $f$ est convexe au voisinage de $z^0_*:=(0,0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons appliquer un algorithme de descente de gradient avec ``line search'' à la fonction $f$. Plus précisément :\n",
    "\n",
    "Étant donné  $z^0=(x^0,y^0)\\in\\mathbb{R}^2$, calculer de manière récursive, jusqu'à convergence,\n",
    "\n",
    "$$\n",
    "\\left|\n",
    "\\begin{array}{lcl}\n",
    "d^k& \\longleftarrow & -\\nabla f(z^k),\\\\\n",
    "\\alpha_k &\\longleftarrow & \\text{Line-search}\\ \\left(\\ t\\mapsto f(z^k + td^k)\\ \\right),\\\\ \n",
    "z^{k+1}&\\longleftarrow &z^k+\\alpha_k d^k\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Précisons la deuxième étape. On remarque d'abord que pour $t>0$,\n",
    "\n",
    "$$\n",
    "f(z^k+t d^k) \\,=\\, f(z^k) -t \\|d^k\\|^2 +o(t).\n",
    "$$\n",
    "\n",
    "En fait, si $f$ est convexe au voisinage de $z^k$, on a aussi pour $t>0$ assez petit, \n",
    "\n",
    "$$\n",
    "f(z^k+t d^k)\\, \\ge\\, f(z^k) -t \\|d^k\\|^2,\n",
    "$$\n",
    "\n",
    "donc on ne peut pas demander $f(z^k+t d^k) \\,\\le\\, f(z^k) -t \\|d^k\\|^2$. \n",
    "\n",
    "L'idée de la *condition Armijo* est de demander un peu moins. Fixons un $c\\in (0,1)$ : la condition Armijo s'écrit : \n",
    "\n",
    "$$\n",
    "\\tag{2}f(z^k+t d^k)\\, \\le\\, f(z^k) -c\\, t \\|d^k\\|^2.\n",
    "$$\n",
    "\n",
    "En utilisant le développement limité ci dessus, on a \n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "f(z^k+t d^k) &=& f(z^k) -t \\|d^k\\|^2 +o(t)\\\\\n",
    "   &=& f(z^k) -c\\, t \\|d^k\\|^2 - (1-c)t\\|d^k\\|^2 +o(t)\\\\\n",
    "   & = & f(z^k) -c\\, t \\|d^k\\|^2 -t \\left[(1-c)\\|d^k\\|^2 +o(1)\\right]\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Pour $t>0$ assez petit, le terme entre crochet est positif et donc (2) est vrai.\n",
    "\n",
    "Nous ne voulons pourtant pas choisir un $\\alpha_k$ trop petit (l'algorithme calerait). Pour éviter cela, nous fixons un pas maximal $\\alpha$ et un facteur $\\beta\\in(0,1)$ et nous testons successivement (2) avec $t=\\alpha$, $t=\\alpha\\beta$, $t=\\alpha\\beta^2$, ... \n",
    "\n",
    "On choisi $\\alpha_k=\\alpha\\beta^j$ où $j$ est le premier entier tel que $t=\\alpha\\beta^j$ vérifie (2).\n",
    "\n",
    "Remarquez que comme $0<\\beta<1$ et que (2) est vraie pour $t>0$ assez petit, cet entier existe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13.** Implémentez la méthode ci-dessus, avec $c=0.5$, $\\beta=0.75$. Commencez par $z^0=(1,0.5)$ et $\\alpha=1$. Ensuite, pour $k\\ge 1$ utilisez $\\alpha\\leftarrow\\alpha_{k-1}/\\beta$.\n",
    "\n",
    "Tout d'abord pour vous aider, la cellule suivante montre quelques ensembles de niveaux de $f$ et le champ de vecteur normalisé $\\dfrac {1}{|\\nabla f|}\\nabla f$ au voisinage de $z^*$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vector_field_2(F, xmin, xmax, ymin, ymax, N=15):\n",
    "    X = np.linspace(xmin, xmax, N)  # x coordinates of the grid points\n",
    "    Y = np.linspace(ymin, ymax, N)  # y coordinates of the grid points\n",
    "    U, V = F(*np.meshgrid(X, Y))  # vector field\n",
    "    M = np.hypot(U, V)  # compute the norm of (U,V)\n",
    "    M[M == 0] = 1  # avoid division by 0\n",
    "    U /= M  # normalize the u componant\n",
    "    V /= M  # normalize the v componant\n",
    "    return plt.quiver(X, Y, U, V, angles='xy')\n",
    "\n",
    "def level_lines_2(f, xmin, xmax, ymin, ymax, levels, N=500):\n",
    "    x = np.linspace(xmin, xmax, N)\n",
    "    y = np.linspace(ymin, ymax, N)\n",
    "    z = f(*np.meshgrid(x, y))\n",
    "    level_l = plt.contour(x, y, z, levels=levels)\n",
    "    #plt.clabel(level_l, levels, fmt='%.1f') \n",
    "\n",
    "f = lambda x, y : np.cosh(x)+ np.sin(x + y)**2\n",
    "df = lambda x, y : np.array([np.sinh(x) + 2*np.cos(x + y)*np.sin(x + y), 2*np.cos(x + y)*np.sin(x + y)])\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(9,6))\n",
    "level_lines_2(f, -1.1, 1.1, -1.1, 1.1, np.linspace(1, 3, 10))\n",
    "draw_vector_field_2(df, -1.1, 1.1, -1.1, 1.1)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x, y : np.cosh(x)+ np.sin(x + y)**2\n",
    "df = lambda x, y : np.array([np.sinh(x) + 2*np.cos(x + y)*np.sin(x + y), 2*np.cos(x + y)*np.sin(x + y)])\n",
    "\n",
    "## Parametres\n",
    "epsilon = 1e-6\n",
    "c, beta = 0.5, 0.75\n",
    "itermax = 500\n",
    "iter_ls_max = 20\n",
    "## initialisation \n",
    "iter = 0\n",
    "x, y, alpha = 1., .5, 1. \n",
    "fz = f(x,y)\n",
    "Z, F =[np.array([x, y])], [fz]\n",
    "flag = 'OK'\n",
    "\n",
    "## Boucle d'optimisation\n",
    "while (iter < itermax):\n",
    "    dx, dy = -df(x, y)\n",
    "    d = np.hypot(dx, dy)\n",
    "    if d < epsilon or flag == 'Not OK':\n",
    "        break\n",
    "    dd =d**2\n",
    "    new_fz = f(x + alpha*dx, y + alpha*dy) \n",
    "    iter_ls = 0\n",
    "    while (new_fz - fz + c*alpha*dd >=0):\n",
    "        alpha *= beta\n",
    "        new_fz = f(x + alpha*dx, y + alpha*dy)\n",
    "        iter_ls += 1\n",
    "        if (iter_ls>=iter_ls_max):\n",
    "            flag = 'Not OK'\n",
    "            break\n",
    "    #print(\"d = \" + str(d) + \", f(z) - 1 =\" + str(fz-1) + \", t= \" +str(t))\n",
    "    x, y, fz = x + alpha*dx, y + alpha*dy, new_fz\n",
    "    Z.append(np.array([x, y]))\n",
    "    F.append(fz)\n",
    "    alpha /= beta\n",
    "    iter += 1\n",
    "\n",
    "print('flag = '+flag + ', n_iter = ' + str(iter))    \n",
    "    \n",
    "Z = np.array(Z)\n",
    "F = np.array(F)\n",
    "\n",
    "# représentations graphiques \n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(Z[:,0],Z[:,1],'.',linestyle='-')\n",
    "level_lines_2(f, -0.5, 1.1, -0.1, 0.55, np.linspace(1, 3, 10))\n",
    "draw_vector_field_2(df, -0.5, 1.1, -0.1, 0.55, 10)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Représentation des valeurs prises par f au cours des itérations.\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.semilogy(range(len(F)),F-1,'.',linestyle='dashed')\n",
    "plt.show()\n",
    "\n",
    "print(\"nbre d'itérations :\", iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère maintenant la fonction définie sur $\\mathbb{R}^3$ par \n",
    "$$\n",
    "f(x,y,z):= \\cosh(x) + \\sin^2(x+y) + (y-z)^2,\\qquad \\text{pour }w=(x,y,z)\\in \\mathbb{R}^3.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14.** Appliquez la méthode d'optimisation ci-dessus à cette fonction, en commençant par $w^0=(1,0.5,1)$ (avec toujours $c=0.5$, $\\beta=0.75$ et $\\alpha=1$ à la première itération)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = lambda w : np.cosh(w[0])+ np.sin(w[0] + w[1])**2 + (w[1] - w[2])**2\n",
    "df = lambda w : np.array([np.sinh(w[0]) + 2*np.cos(w[0] + w[1])*np.sin(w[0] + w[1]), \n",
    "                                2*np.cos(w[0] + w[1])*np.sin(w[0] + w[1]) + 2*(w[1] - w[2]),  2*(w[2] - w[1])])\n",
    "\n",
    "## Paramètres\n",
    "epsilon = 1e-6\n",
    "c, beta = 0.5, 0.75\n",
    "itermax = 200\n",
    "iter_ls_max =30\n",
    "\n",
    "## initialisation \n",
    "iter = 0\n",
    "w, alpha = np.array([1., .5, 4.]) , 1.\n",
    "fw = f(w)\n",
    "W, F =[w], [fw]\n",
    "flag = 'OK'\n",
    "\n",
    "## Boucle d'optmization\n",
    "while (iter < itermax):\n",
    "    d = -df(w)\n",
    "    norm_d = np.linalg.norm(d)\n",
    "    if norm_d < epsilon or flag == 'Not OK':\n",
    "        break\n",
    "    dd =norm_d**2\n",
    "    new_fw = f(w + alpha*d)\n",
    "    iter_ls = 0\n",
    "    while (new_fw - fw + c*alpha*dd >=0):\n",
    "        alpha *= beta\n",
    "        new_fw = f(w + alpha*d) \n",
    "        iter_ls += 1\n",
    "        if (iter_ls>=iter_ls_max):\n",
    "            flag = 'Not OK'\n",
    "            break\n",
    "    #print(\"norm_d = \" + str(norm_d) + \", f(w) - 1 =\" + str(fw-1) + \", t= \" +str(t))\n",
    "    w, fw = w + alpha*d, new_fw\n",
    "    alpha /= beta\n",
    "    W.append(w)\n",
    "    F.append(fw)\n",
    "    iter += 1\n",
    "\n",
    "print('flag = '+flag + ', n_iter = ' + str(iter) + ', itermax = ' + str(itermax))   \n",
    "\n",
    "\n",
    "# Représentation des itérés.\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "W = np.array(W)\n",
    "x, y, z = W[:,0], W[:,1], W[:,2]\n",
    "ax = Axes3D(plt.figure())  # Define the 3D plot\n",
    "ax.set(xlabel=r'$x$', ylabel=r'$y$', zlabel=r'$z$')\n",
    "ax.plot(x, y, z,'.')  # Plot of the trajectory\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Représentation des valeurs prises par f au cours des itérations\n",
    "F = np.array(F)\n",
    "plt.figure()\n",
    "plt.semilogy(range(len(F)), F-1, '.', linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
