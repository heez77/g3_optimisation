{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnjzW0-TPMvF"
   },
   "source": [
    "# __Gradient Stochastique et régularisation  $\\ell^1$__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a id='toc'></a>Sommaire</h1>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ul>\n",
    "        <li><a href=\"#I\">I. Introduction </a></li>\n",
    "        <ul>\n",
    "        <li><a href=\"#I1\">I.1. Un exemple en dimension 1</a></li>\n",
    "        <li><a href=\"#I2\">I.2. Un cas degeneré</a></li>\n",
    "        <li><a href=\"#I3\">I.3. Un exemple en plus grande dimension </a></li>\n",
    "        </ul>\n",
    "        <li><a href=\"#II\">II. Optimisation numérique de $F_\\lambda$ par ISTA</a></li>\n",
    "        <ul>\n",
    "            <li><a href=\"#II1\">II.1. Réinterpretation de la méthode du gradient à pas constant</a></li> \n",
    "            <li><a href=\"#II2\">II.2. ISTA </a></li> \n",
    "        </ul>\n",
    "        <li><a href=\"#III\">III. Application à l'optimisation stochastique</a></li>\n",
    "    </ul>\n",
    "</div>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ie13pHt3gyh8"
   },
   "source": [
    "Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from toynn_2023 import *\n",
    "# charge aussi les bibliothèques suivantes :\n",
    "#    import numpy as np\n",
    "#    from numpy import random as nprd\n",
    "#    from matplotlib import pyplot as plt\n",
    "#    from matplotlib import cm as cm\n",
    "#    from copy import deepcopy as dcp\n",
    "import math as mt\n",
    "from numpy import linalg as ln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction <a id='I'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut optimiser une fonction objectif régulière et convexe $F(w)$ mais on veut aussi privilégier les solutions parcimonieuses, c'est-à-dire les paramètres $w$ avec un grand nombre de composantes nulles. Pour cela, nous pénalisons la fonction objectif en ajoutant le terme ``régularisant'' $\\lambda\\|w\\|_1$. Ici $\\lambda\\geq0$ est le paramètre de pénalisation et\n",
    "$$\n",
    "\\|w\\|_1 :=\\sum_{j=0}^{N-1}|w_j|=|w_0|+|w_1|+\\dots+|w_{N-1}|\n",
    "$$\n",
    "est la norme $\\ell^1$ du vecteur $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='I1'></a>\n",
    "<h2>I.1. Un exemple en dimension 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons d'abord le cas $N=1$. Soit $\\,\\bar w\\in\\mathbb{R}\\,$. On définit $\\,f(w)=\\frac12|w-\\bar w|^2\\,$ et pour $\\,\\lambda\\ge 0\\,$, on pose\n",
    "$$\\,f_\\lambda(w):=f(w)+\\lambda\\|w\\|_1\\,=\\, \\frac12|w-\\bar w|^2+\\lambda|w|.$$\n",
    "Le minimiseur de $\\,f\\,$ est évidemment $\\,\\bar w\\,$. Dans quelle mesure est-il perturbé par le terme régularisant ? Découvrons-le en calculant le minimiseur de $\\,f_\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques préliminaires.** La fonction $f$ est strictement convexe (elle est 1-convexe) et $w\\mapsto |w|$ est convexe donc la fonction résultante $f_\\lambda$ est $1$-convexe. Nous concluons que $f_\\lambda$ admet un unique minimiseur. On le note $w^*$ comme d'habitude.\n",
    "\n",
    "Pour $\\lambda>0$, la fonction $f_\\lambda$ n'est pas dérivable en $0$. Cependant, elle  est dérivable en tout point $w\\neq0$ et si $w^*\\neq 0$, on a la condition d'optimalité\n",
    "\n",
    "$$\n",
    "0=f'_\\lambda(w^*)=w^*-\\bar w +\\lambda \\mathop{signe}(w^*). \\tag{0}\n",
    "$$\n",
    "Inversement, si (0) est vrai en point $\\hat w\\neq0$, alors $\\hat w =w^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'analyse on considère quatre cas selon les valeurs de $\\bar w$ et $\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Premier cas**$\\,$ Si $\\bar w=0$, on a évidemment $w^*=0$ $~~$($\\,f_\\lambda(0)=0\\,$ et $\\, f_\\lambda(w)>0\\,$ si $\\,w\\neq0\\,$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Deuxième cas**$\\,$ Si $\\lambda=0\\,$ alors $\\,f_\\lambda(w)=f(w)=\\frac12|w-\\bar w|^2\\,$ et le minimiseur est $\\,w^*=\\bar w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Troisième cas** Nous supposons $\\lambda>0\\,$ et $\\,\\bar w>0\\,$. Nous remarquons d'abord que $\\,w^*\\geq 0$.\n",
    "En effet, pour $\\,w<0\\,$, il existe $\\quad|w-\\bar w|= \\bar w - w>\\bar w = |0-\\bar w|,\\quad $ so\n",
    "$\\quad\n",
    "f_\\lambda(w)>f_\\lambda(0)\\geq f_\\lambda(w^*)\n",
    "\\quad$ et nous voyons que $\\,w^*\\neq w$.\n",
    "\n",
    "Ensuite, si $\\,w^*>0\\,$, alors par (0) nous avons $\\,w^*=\\bar w-\\lambda$. Ce nombre est positif si et seulement si $\\,\\bar w>\\lambda$. Nous concluons que :\n",
    "\n",
    "$$\n",
    "w^*=\\begin{cases}\\bar w-\\lambda &\\text{if } \\bar w>\\lambda,\\\\\n",
    "\\quad 0 & \\text{if } 0<\\bar w\\leq\\lambda. \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Quatrième cas** Nous supposons toujours $\\,\\lambda>0\\,$ mais $\\,\\bar w<0$. En raisonnant comme ci-dessus, on voit que $\\,w^*\\leq 0\\,$ puis\n",
    "\n",
    "$$\n",
    "w^*=\\begin{cases}\\bar w+\\lambda &\\text{if } \\bar w<-\\lambda,\\\\\n",
    "\\quad 0 & \\text{if } -\\lambda\\leq \\bar w<0. \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** $\\,$En résumé :\n",
    "$$\n",
    "w^*=\\begin{cases}\\bar w-\\lambda\\ \\text{sign}\\,\\bar w &\\text{if } |\\bar w|>\\lambda,\\\\\n",
    "\\qquad 0 & \\text{if } |\\bar w|\\leq \\lambda. \\end{cases}\n",
    "$$\n",
    "\n",
    "On peut mesurer la distance entre le minimiseur de $\\,f\\,$ et le minimiseur de $\\,f_\\lambda\\,$ :\n",
    "\n",
    "$$\n",
    "|\\bar w|>\\lambda\\ \\Longrightarrow\\ |w^* -\\bar w|=\\lambda\\qquad\\text{and}\\qquad\n",
    "|\\bar w|\\le\\lambda\\ \\Longrightarrow\\ |w^* -\\bar w|=|\\bar w|.\n",
    "$$\n",
    "\n",
    "Dans tous les cas :$\\qquad\\qquad\\qquad\\qquad\\qquad|w^* -\\bar w|\\leq \\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les tracés du graphique de la fonction $\\bar w\\mapsto w^*$ pour $\\lambda =0$, $\\lambda=1$, $\\lambda=2$ et $\\lambda=4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 12})\n",
    "if 1==1:\n",
    "    buildf_lbda = lambda L: lambda w: np.where(w>L, w-L, \n",
    "                                               np.where( w<-L, w+L, 0))\n",
    "    lbda = (0 , 1, 2 , 4)\n",
    "    w=np.linspace(-10,10,41)\n",
    "    plt.figure(figsize=(16,3.5))\n",
    "    for i in range(4):\n",
    "        plt.subplot(141 + i)\n",
    "        plt.plot([-10, 10], [0, 0],'r',linewidth=.5, label='axes')\n",
    "        plt.plot([0, 0], [-10, 10],'r',linewidth=.5)\n",
    "        plt.plot(w, buildf_lbda(lbda[i])(w))\n",
    "        plt.title(f\"case $\\lambda=$\" + str(lbda[i]))\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='I2'></a>\n",
    "<h2>I.2. Un cas dégénéré</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On considère ici, $N=2$ et \n",
    "$$\n",
    "F(w):=\\dfrac12(2w_0 + w_1 - 1)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1**\n",
    "\n",
    "a) La fonction $F$ est-elle convexe ? fortement convexe ? coercive?\n",
    "\n",
    "b) Trouvez les minimiseurs dans $\\mathbb{R}^2$ de $F$.\n",
    "\n",
    "c) Soit $\\lambda>0$. Trouvez les minimiseurs de\n",
    "\n",
    "$$\n",
    "F_\\lambda(w)=F(w)+\\lambda\\|w\\|_1:= \\dfrac12(2w_0 + w_1 - 1)^2 +\\lambda (|w_0| +|w_1|).\n",
    "$$\n",
    "\n",
    "*__Indication :__ justifier que si la compososante $w^*_j$ d'un point de minimum $w^*$ est non nulle alors $\\dfrac {\\partial F_\\lambda(w^*)}{\\partial w_j}$ est bien défini et nul.*\n",
    "\n",
    "d) Interprétez le résultat de (c) : quels sont les effets du terme régularisant $\\lambda \\|w\\|_1$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top : 0px\">\n",
    "    \n",
    "___Solution 1.a.___\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tant que polynome de 2 variables, $F(\\omega)$ est $\\mathbf{C}^2$ et on peut calculer sa hessienne.\n",
    "\n",
    "$\\forall \\omega \\in \\mathbb{R}^2$\n",
    "\n",
    "$H(\\omega) = \\begin{bmatrix}\n",
    "4 & 2\\\\\n",
    "2 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\forall \\omega \\in \\mathbb{R}^2, H(\\omega) \\in \\mathbf{S}^+$ (symétrique postive) et $F$ est convexe.\n",
    "\n",
    "Néanmoins, $0$ est valeur propre de $H$ $(det(H)=0)$ et $F$ n'est pas fortement convexe car la matrice n'est pas définie positive. \n",
    "\n",
    "De plus, $F$ s'annule sur la droite $2w_0 + w_1 - 1 = 0$ et $F$ ne tend pas vers $+ \\infty$ sur cette droite donc $F$ n'est pas coercive. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top : 0px\">\n",
    "    \n",
    "___Solution 1.b.___\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$F$  est positive et s'annule seulement sur la droite  $2w_0 + w_1 - 1 = 0$ donc les minimiseurs de $F$ sont l'ensemble des points de cette droite.\n",
    "On retrouve cela en calculant le gradient de $F$.\n",
    "$$ \\nabla F (w^*) = \\begin{bmatrix}\n",
    "2(2w_0 + w_1 - 1 ) \\\\\n",
    "2w_0 + w_1 - 1  \n",
    "\\end{bmatrix} = 0 $$\n",
    "\n",
    "Et on trouve le même résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top : 0px\">\n",
    "    \n",
    "___Solution 1.c.___\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$F_\\lambda$ est dérivable en dehors des droites $w_0=0$ et $w_1 = 0$ (à cause de la norme 1 qui fait intervenir des valeurs absolues dérivables hors des 0) et :\n",
    "$$ \\dfrac {\\partial F_\\lambda(w)}{\\partial w_0} =\\begin{cases} 2(2w_0 + w_1 - 1 ) + \\lambda& \\text{si }  w_0>0,\\\\\n",
    "2(2w_0 + w_1 - 1 ) - \\lambda & \\text{si } w_0<0. \\end{cases} = 0$$ \n",
    "$$ \\dfrac {\\partial F_\\lambda(w)}{\\partial w_1} =\\begin{cases} 2w_0 + w_1 - 1  + \\lambda& \\text{si }  w_1>0,\\\\\n",
    "2w_0 + w_1 - 1 - \\lambda & \\text{si } w_1<0. \\end{cases} = 0$$\n",
    "\n",
    "Ainsi, en couplant ces équations, on arrive à des contradictions sur $\\lambda = 0$ donc on regarde sur un droite $w_i = 0$ \n",
    "\n",
    "Sur $\\{w_0=0\\}, F(w) = (w_1-1)^2 +\\lambda|w_1|$ et \n",
    "$$\\dfrac {\\partial F_\\lambda(w)}{\\partial w_1} =\\begin{cases}  w_1 - 1  + \\lambda& \\text{si }  w_1>0,\\\\\n",
    " w_1 - 1 - \\lambda & \\text{si } w_1<0. \\end{cases} = 0 \\Leftrightarrow \\begin{cases}  w_1 = 1  - \\lambda& \\text{si }  w_1>0,\\\\\n",
    " w_1 = 1 + \\lambda & \\text{si } w_1<0. \\end{cases}$$\n",
    "\n",
    "Sur $\\{w_1=0\\}, F(w) = (2w_0-1)^2 +\\lambda|w_0|$ et \n",
    "$$\\dfrac {\\partial F_\\lambda(w)}{\\partial w_0} =\\begin{cases} 2w_0 - 1  + \\lambda& \\text{si }  w_0>0,\\\\\n",
    " 2w_0 - 1 - \\lambda & \\text{si } w_0<0. \\end{cases} = 0 \\Leftrightarrow \\begin{cases} w_0 = \\dfrac{ 1  - \\lambda}{2}& \\text{si }  w_0>0,\\\\\n",
    " w_0 = \\dfrac{1 + \\lambda}{2} & \\text{si } w_0<0. \\end{cases} $$\n",
    "\n",
    "\n",
    "Ainsi, on trouve 2 points au maximum qui sont les minimiseurs de la fonction et ils sont sur les droites $\\{w_0=0\\}$ et $\\{w_1=0\\}$\n",
    "\n",
    "$\\Rightarrow w^* = \\begin{cases} (0,0) \\\\\n",
    " (0,1-\\lambda) \\text{ si } 0<\\lambda<1.\\\\\n",
    " (\\dfrac{1}{2}-\\dfrac{\\lambda}{4},0) \\text{ si } 2<\\lambda\\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top : 0px\">\n",
    "    \n",
    "___Solution 1.d.___\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La régularisation réduit le nombre de racine. On passe d'une infinité de minimiseurs à un nombre fini. Les algorithmes d'optimisation auront donc des minimum locaux stricts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='I3'></a>\n",
    "<h2>I.3. Un exemple en plus grande dimension</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons maintenant une fonction quadratique non dégénérée comme en **I.1** mais en dimension supérieure $N\\geq 1$. Nous fixons $\\bar w\\in \\mathbb{R}^N$ et une suite de nombres $a_0,a_1,\\dots,a_{N-1}>0$ et nous posons pour $w\\in\\mathbb{ R}^N$,\n",
    "\n",
    "$$\\tag{1}\n",
    "F(w):=\\dfrac12\\sum_{j=0}^{N-1} a_j (w_j-\\bar w_j)^2\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\n",
    "\\qquad\\qquad=\\dfrac{a_0}2(w_0-\\bar w_0)^2 + \\dfrac{a_1}2(w_1-\\bar w_1)^2+\\dots + \\dfrac{a_{N-1}} 2(w_{N-1}-\\bar w_{N-1})^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme dans la partie <a href=\"#I1\">I.1.</a> la fonction $\\,F\\,$ est fortement convexe : elle est $\\gamma$-convexe pour\n",
    "$$\\gamma=\\min\\{a_j,j=0,\\dots,N-1\\}\\, >0.$$\n",
    "On note $\\,\\bar w\\,$ l'unique minimiseur de $\\,F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixons $\\lambda>0$ et fixons comme plus haut, $F_\\lambda(w):=F(w)+\\lambda \\|w\\|_1$. La fonction $F_\\lambda$ est à nouveau fortement convexe, on note son unique minimiseur $w^*$. \n",
    "\n",
    "À quelle distance de $w^*$ se trouve $\\bar w$ ? À quel point est-il plus parcimonieux que $\\bar w$ ? Pour le savoir nous allons déterminer explicitement $w^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquons tout d'abord que $F_\\lambda$ se divise en $N$ fonctions d'un seul paramètre :\n",
    "\n",
    "$$\n",
    "F_\\lambda(w)=\\sum_{j=0}^{N-1} F^{(j)}_\\lambda (w_j)\\qquad\n",
    "\\text{with}\\quad F^{(j)}_\\lambda (w_j)=\\dfrac{a_j}2(w_j-\\bar w_j)^2 + \\lambda |w_j|\n",
    "= a_j\\left\\{\\dfrac12(w_j-\\bar w_j)^2 + \\dfrac{\\lambda}{a_j} |w_j|\\right\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque les paramètres des fonctions $F_\\lambda^{(j)}$ sont indépendants les uns des autres, nous pouvons optimiser séparément les $F_\\lambda^{(j)}$. L'expression entre accolades est de la forme $f_{\\lambda/a_j}(w_j)$ étudiée en <a href=\"#I1\">I.1.</a>. Nous en déduisons que\n",
    "\n",
    "$$\\tag{2}\n",
    "\\text{Pour }j=0,\\dots,N-1,\\ \\quad w^*_j=\\begin{cases}\\bar w_j-\\dfrac\\lambda{a_j}\\ \\text{signe}\\, \\bar w_j &\\text{si } |a_j\\bar w_j|>\\lambda,\\\\\n",
    "\\qquad 0 &\\text{si } |a_j\\bar w_j|\\leq \\lambda. \\end{cases}\n",
    "$$\n",
    "\n",
    "Notez que $|a_j\\bar w_j|= \\left| \\dfrac{\\partial F}{\\partial w_j}(0)\\right|$ mesure la sensibilité de $F$ par rapport aux variations de la $j$-ième variable ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons interpréter la formule ci-dessus comme suit :\n",
    "\n",
    "$\\quad\\ $a) si cette sensibilité est suffisamment petite, _c'est-à-dire_ $\\ \\left| \\dfrac{\\partial F}{\\partial w_j}(0)\\right|\\leq \\lambda\\ $ alors $w^*_j$ vaut 0. On a alors\n",
    "$$\n",
    "\\tag{3a}\n",
    "|a_j(w^*_j - \\bar w_j)| \\leq\\lambda.\n",
    "$$\n",
    "\n",
    "\n",
    "$\\quad\\ $b) pour des sensibilités plus grandes $\\ \\left| \\dfrac{\\partial F}{\\partial w_j}(0)\\right| > \\lambda\\ $, $w^*_j$ est une approximation de $\\bar w_j$, avec\n",
    "$$\n",
    "\\tag{3b}\n",
    "|a_j(w^*_j - \\bar w_j)| =\\lambda.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque :** En réinterprétant (3a) et (3b) en fonction des composantes de $\\nabla F$, on voit que pour chaque $j$\n",
    "$$\n",
    "\\left|\\dfrac{\\partial F(w^*)}{\\partial w_j} \\right|\\leq\\lambda.\n",
    "$$\n",
    "Plus précisément, si on fixe tous les $\\,w_k^*\\,$ pour $k\\,\\neq j\\,$,\n",
    "\n",
    "$$\\tag{4}\n",
    "\\text{le terme est $\\,w_j^*\\,$ minimise $\\,|w_j|\\,$ dans l'ensemble }\\\\\n",
    "\\left\\{w_j\\in\\mathbb{R}\\ :\\ \\left|\\dfrac{\\partial F}{\\partial w_j}\\right|(w^*_0,\\dots,w^*_{j-1 },w_j,w^*_{j+1},\\dots, w^*_{N-1})\\leq\\lambda\\right\\}.\n",
    "$$\n",
    "\n",
    "Ceci est également vrai pour toute fonction convexe $F$ de classe $C^1$, pas seulement pour les fonctions quadratiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons que si nous choisissons $\\lambda$ petit, $w^*$ sera une petite perturbation du minimiseur exact de $F$. De plus, si mettre $w^*_j$ à 0 ne crée qu'un gradient négligeable (inférieur à $\\lambda$) alors $w^*_j$ vaut 0. En ce sens, la régularisation favorise la *parcimonie* de $w^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Optimisation numérique de $F_\\lambda$ par ISTA<a id='II'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(__ ***''ISTA'' signifie ``Iterative Shrinkage-Thresholding Algorithm''*** __)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons optimiser une fonction convexe régulière $F:\\mathbb{R}^N\\to \\mathbb{R}$ avec un terme de régularisation $\\lambda \\|w\\|_1$ où le paramètre $\\lambda\\geq 0$ est donné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='II1'></a>\n",
    "<h2>II.1. Réinterpretation de la méthode du gradient à pas fixe</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposons d'abord $\\,\\lambda =0$. Dans ce cas $\\,F_\\lambda=F\\,$ est régulière et nous pouvons utiliser la méthode de gradient avec pas fixe $\\,\\alpha>0$. Nous commençons par réinterpréter cette méthode comme une succession de résolutions de problèmes d'optimisation. Nous commençons par un vecteur initial $\\,w^0\\in\\mathbb{R}^N\\,$ et nous construisons récusivement la suite $w^0$, $w^1$,$w^2$, $\\ points$, avec les règles suivantes :\n",
    "\n",
    "$\\qquad$a) A l'étape $\\,k$, connaissant l'itération courante $\\,w^k$, on définit la fonction\n",
    "\n",
    "$$\\tag{5}\n",
    "\\Phi^k(w):=F(w^k) +\\left<\\nabla F(w^k);w-w^k\\right> + \\dfrac1{2\\alpha}\\|w-w^k\\|^ 2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour construire la fonction $\\,\\Phi^k\\,$ nous sommes parti du développement de Taylor au premier ordre de $F$ et nous avons ajouté le terme quadratique $\\,\\|w-w^k\\|^2/(2\\alpha)$.  $\\Phi^k$ est donc une approximation (au premier ordre) de $\\,F\\,$ près de $\\,w^k\\,$ et est une fonction quadratique définie positive.\n",
    "En particulier, il admet un minimiseur unique.\n",
    "\n",
    "$\\qquad$b) $w^{k+1}\\,$ est défini comme le minimiseur de $\\,\\Phi^k$.\n",
    "\n",
    "Il est facile de déterminer le minimiseur de la fonction quadratique $\\Phi^k$. Nous trouvons\n",
    "\n",
    "$$\n",
    "\\tag{6}\n",
    "w^{k+1} = w^k - \\alpha \\nabla F(w^k)\n",
    "$$\n",
    "\n",
    "Comme annoncé, nous retrouvons la formule donnant $\\,w^{k+1}\\,$ en fonction de $w^k$ pour la méthode de descente de gradient de pas $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2** Justifier la formule (6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 0px\">\n",
    "    \n",
    "___Solution 2.___ \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Phi^k$ admet un minimiseur unique.\n",
    "\n",
    "$$\n",
    "\\nabla\\Phi^k(w^{k+1}) = \\nabla F(w^k) + \\dfrac1{\\alpha}(w^{k+1} - w^k) = \\nabla F(w^k)-\\nabla F(w^k) = 0\n",
    "$$\n",
    "Et $w^{k+1}$ est bien définie en tant que minimiseur de $\\Phi^k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='II2'></a>\n",
    "<h2>II.2. ISTA</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous supposons maintenant $\\lambda>0$ de sorte qu'on a un terme de régularisation $\\ell^1$. Pour optimiser $F_\\lambda$, nous partons toujours d'une estimation initiale $w^0$ et construisons récursivement une suite $w^0$, $w^1$, $w^2$, $\\dots$ où à l'étape $k,\\,$ $w^{k+1}$ est défini comme le minimiseur de\n",
    "\n",
    "$$\\tag{7}\n",
    "\\Phi_\\lambda^k(w):= \\Phi^k(w)+\\lambda \\|w\\|_1.\n",
    "$$\n",
    "\n",
    "Notez que nous **ne remplaçons pas** le terme de pénalisation par son développement de Taylor au voisinage de $w^k$.\n",
    "\n",
    "En rappelant la définition de $\\ \\Phi^k,\\ $ nous avons\n",
    "$$\\tag{8}\n",
    "\\Phi_\\lambda^k(w)=F(w^k) +\\left<\\nabla F(w^k);w-w^k\\right> + \\dfrac1{2\\alpha}\\|w-w^k\\| ^2 +\\lambda\\|w\\|_1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pouvons-nous trouver une formule explicite pour $w^{k+1}$ ? Oui! En fait, nous sommes dans la situation de **I.2.** Notons $\\,\\bar w^k\\,$ le minimiseur de $\\,\\Phi^k$. Par (6) nous avons\n",
    "\n",
    "$$\\tag{9}\\bar w^k=w^k-\\alpha\\nabla F(w^k)$$\n",
    "\n",
    "et la fonction $\\Phi^k$ se réécrit comme\n",
    "$$\\tag{10}\n",
    "\\Phi^k(w) = c_k + \\dfrac1{2\\alpha} \\|w - \\bar w^k\\|_2^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3** Justifier la formule (10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 0px\">\n",
    "    \n",
    "___Solution 3.___\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Phi^k(w) = c_k + \\dfrac1{2\\alpha} \\|w -  \\bar w^k\\ \\|_2^2 = c_k + \\dfrac1{2\\alpha} \\|w -  w^k + \\alpha\\nabla F(w^k) \\|_2^2 = c_k+ \\left<\\nabla F(w^k);w-w^k\\right> + \\dfrac1{2\\alpha}\\|w-w^k\\|^2 +\\frac{\\alpha}{2}\\|\\nabla F(w^k)\\|^2$ \n",
    "\n",
    "En posant $c_k = F(w_k) - \\frac{\\alpha}{2}\\|\\nabla F(w^k)\\|^2$, on trouve le résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tenant compte de (7) et (10) on voit que $w^{k+1}$ est le minimiseur de\n",
    "$$\n",
    "G(w):=\\dfrac1{2\\alpha} \\|w - \\bar w_k\\|_2^2 + \\lambda \\|w\\|_1.\n",
    "$$\n",
    "Cette fonction est de la forme (1) dans la partie **I.2.** avec $a_0=a_1=\\dots=a_{N-1}=1/\\alpha$. Ainsi, en utilisant la formule (2), nous avons\n",
    "\n",
    "$$\\tag{11}\n",
    "\\text{pour }j=0,\\dots,N-1,\\ \\ w^{k+1}_j=\n",
    "\\begin{cases} \\bar{w}^k_j - \\lambda\\alpha\\ \\text{sign}\\, \\bar w^k_j &\n",
    "\\text{si } |\\bar{w}^k_j| > \\lambda\\alpha ,\\\\\n",
    "\\qquad 0 &\n",
    "\\text{si } |\\bar{w}^k_j| \\leq \\lambda\\alpha. \\end{cases}\\qquad\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé.** Nous déduisons de (9) et (11) une formule explicite pour $w^{k+1}$. Après l'initialisation, ISTA s'exécute comme suit : pour $k=0,1,\\dots$ calculer\n",
    "$$\\tag{12}\n",
    "\\begin{array}{rl} \\hfill\\bar{w}^k :=&w^k-\\alpha\\nabla F(w^k), \\\\ \\\\\n",
    "\\text{pour }j=0,\\dots,N-1,\\quad \\ w^{k+1}_j:=&\n",
    "\\begin{cases} \\bar{w}^k_j - \\lambda\\alpha\\ \\text{sign}\\, \\bar w^k_j &\n",
    "\\text{si } |\\bar{w}^k_j| > \\lambda\\alpha ,\\\\\n",
    "\\qquad 0 &\n",
    "\\text{si } |\\bar{w}^k_j| \\leq \\lambda\\alpha. \\end{cases}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 4** Nous souhaitons tester cet algorithme avec\n",
    "$$\n",
    "F(w):=\\sum_{j=0}^{N-1} \\sin^2(\\pi (w_j - w^*_j)),\n",
    "$$\n",
    "où la suite $w^*_0,\\dots,w^*_{N-1}$ est donnée.<br>\n",
    "Justifiez la formule pour $\\nabla F$ donnée ci-dessous dans la définition de la fonction python  _builGradF_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 0px\">\n",
    "    \n",
    "    \n",
    "___Solution 4.___ \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\forall w, \\dfrac{\\partial F}{\\partial w_m} = \\sum_{j=0}^{N-1} 2\\pi\\delta_{jm}\\cos(\\pi (w_j - w^*_j))\\sin(\\pi (w_j - w^*_j))$\\\n",
    "$= 2\\pi\\cos(\\pi (w_m - w^*_m))\\sin(\\pi (w_m - w^*_m)) =\\pi\\sin(2\\pi (w_m - w^*_m)) $\n",
    "\n",
    "On obtient ainsi le gradient de $F$ :\n",
    "$$\\forall w, \\nabla F(w) = \\left[  \\pi\\sin(2\\pi (w_i - w^*_i))\\right]_{i \\in \\{ 1, \\,...\\, ,N-1\\}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exemple d'une fonction régulière non convexe\n",
    "\n",
    "# Constructeur de F et Grad F\n",
    "buildF = lambda barw : lambda w : np.sum(\n",
    "                            np.sin(np.pi*(w - barw))**2 )\n",
    "buildGradF = lambda barw : lambda w : np.pi*np.sin(2*np.pi*(w - barw))\n",
    "\n",
    "# Fonction pour compter le nombre de composantes non nulles d'un vecteur\n",
    "count_non_zeros= lambda w: np.sum(np.where(w==0, 0, 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5** Mettez en oeuvre ISTA (compléter la quatrième boîte ci-dessous) pour la fonction précédente. On prendra $N=100$ et $\\lambda=2$. \n",
    "\n",
    "Faites des représentations graphiques des valeurs prises par $F_\\lambda$ au cours des itérations, ainsi que du nombre de composantes non nulles de chaque itéré.<br>\n",
    "\n",
    "Faites varier la valeur de $\\lambda$ et noter vos observations et commentaires dans la boîte dédiée.\n",
    "\n",
    "_Indication :_ La méthode numpy _np.where_ peut se révéler utile. Si _w_ est un tableau numpy, disons un vecteur, la  commande\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "v$=$np.where(abs(w)<1, f(w), g(w))<br>\n",
    "construit un tableau numpy _v_ de même taille que _w_ avec la règle suivante.   \n",
    "$$\n",
    "\\text{v}[i]=\\begin{cases} \\text{f}(\\text{w}[i])&\\text{si }\\text{abs}(\\text{w}[i])<1,\\\\\n",
    "\\text{g}(\\text{w}[i])&\\text{sinon}.\\end{cases}\n",
    "$$\n",
    "\n",
    "Nous indiquons aussi que la norme $\\ell^1$ d'un tableau numpy _w_ s'obtient à la l'aide de la méthode _numpy.linalg.norm_. Par exemple, la commande<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "norme_l1$=$ln.norm(w, ord=1))<br>\n",
    "calcule la somme  $\\sum_i$*w*[$i$] (et attribue cette valeur à la variable *norme_l1*).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Préliminaire pour l'exercice 5)\n",
    "# Construction du problème\n",
    "N = 100\n",
    "w_star = .5*nprd.random(N) - .25\n",
    "F, GradF = buildF(w_star), buildGradF(w_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Préliminaire pour l'exercice 5)\n",
    "# Paramètres de l'algorithme d'optimisation \n",
    "alpha = .1\n",
    "Lambda = 2\n",
    "threshold = alpha*Lambda # threshold\n",
    "Nitermax =15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def methodeISTA(Lambda,Nitermax):\n",
    "    N = 100\n",
    "    # Paramètres de l'algorithme d'optimisation\n",
    "    alpha = .1\n",
    "    Lambda = Lambda\n",
    "    threshold = alpha*Lambda\n",
    "    Nitermax =Nitermax\n",
    "    w = .5*nprd.random(N) - .25\n",
    "    niter=0\n",
    "    # Listes de stockage\n",
    "    E = [(F(w) + Lambda*ln.norm(w, ord=1))]\n",
    "    NZ = [count_non_zeros(w)]\n",
    "    Fv=[F(w)]\n",
    "    W = [w]\n",
    "    while (niter < Nitermax):\n",
    "        dF = GradF(w)\n",
    "        wbar = w - alpha*dF\n",
    "        w= np.where(np.abs(wbar)<=threshold,0,np.where(wbar>0,wbar-threshold,wbar+threshold))\n",
    "        W.append(w)\n",
    "        Fv.append(F(w))\n",
    "        E.append ((F(w) + Lambda*ln.norm(w, ord=1)))\n",
    "        NZ.append(count_non_zeros(w))\n",
    "        niter += 1\n",
    "    W=np.array(W)\n",
    "    return (Fv,E,NZ,W)   #(F_lambda,F,NZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Préliminaire pour l'exercice 5)\n",
    "# Initialisation\n",
    "w = .5*nprd.random(N) - .25\n",
    "niter=0\n",
    "\n",
    "# On créé deux listes pour l'analyse du comportement de l'algorithme d'optimisation.\n",
    "# La liste E pour stocker les valeurs de la fonction à minimiser.\n",
    "E = [(F(w) + Lambda*ln.norm(w, ord=1))]\n",
    "# La liste NZ pour stocker le nombre d'éléments non nuks des w^k.\n",
    "NZ = [count_non_zeros(w)] \n",
    "Fv=[F(w)]\n",
    "\n",
    "## Solution 5\n",
    "W = [w]\n",
    "while (niter < Nitermax):\n",
    "    dF = GradF(w)\n",
    "    wbar = w - alpha*dF\n",
    "    #w = (np.abs(wbar)>threshold)*(w - threshold*np.sign(wbar))\n",
    "    w= np.where(np.abs(wbar)<=threshold,0,np.where(wbar>0,wbar-threshold,wbar+threshold))\n",
    "    W.append(w)\n",
    "    Fv.append(F(w))\n",
    "    E.append ((F(w) + Lambda*ln.norm(w, ord=1)))\n",
    "    NZ.append(count_non_zeros(w))\n",
    "    niter += 1\n",
    "W=np.array(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 5 (suite) Représentations graphiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(Fv)\n",
    "plt.title('Evolution de la fonction F')\n",
    "plt.xlabel(\"nombre d'itérations\")\n",
    "plt.ylabel(\"F(w)\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.linspace(0,Nitermax,Nitermax+1),NZ)\n",
    "plt.title('Evolution du nombre de composantes non nulles de w')\n",
    "plt.xlabel(\"nombre d'itérations\")\n",
    "plt.ylabel(\"nombre de composantes non nulles\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(E)\n",
    "plt.title('Evolution de la fonction F_lambda')\n",
    "plt.xlabel(\"nombre d'itérations\")\n",
    "plt.ylabel(\"F_lambda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 0px\">\n",
    "    \n",
    "___Solution 5___. (commentaires). \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation de $\\lambda$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lambda0=0.5\n",
    "plt.figure()\n",
    "plt.ylim(top=15) #ymax is your value\n",
    "plt.ylim(bottom=0) #ymin is your value\n",
    "for i in range (0,7):\n",
    "    Lambda=Lambda0+i*0.1\n",
    "    (Fv,E,NZ,W)=methodeISTA(Lambda,20)\n",
    "    plt.plot(Fv,label='lambda = '+str(Lambda))\n",
    "plt.title('Evolution de la fonction F')\n",
    "plt.xlabel(\"nombre d'itérations\")\n",
    "plt.ylabel(\"F\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "for i in range (0,7):\n",
    "    Lambda=Lambda0+i*0.1\n",
    "    (Fv,E,NZ,W)=methodeISTA(Lambda,20)\n",
    "    plt.plot(np.linspace(0,20,21),NZ,label='lambda = '+str(Lambda))\n",
    "plt.title('Evolution du nombre de composantes non nulles de w')\n",
    "plt.xlabel(\"nombre d'itérations\")\n",
    "plt.ylabel(\"nombre de composantes non nulles\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que augmenter la valeur de lambda permet d'augmenter le nombre de composantes nulles de w. C'est normal au vu de la méthode ISTA :\n",
    "\\begin{cases} \\bar{w}^k_j - \\lambda\\alpha\\ \\text{sign}\\, \\bar w^k_j &\n",
    "\\text{si } |\\bar{w}^k_j| > \\lambda\\alpha ,\\\\\n",
    "\\qquad 0 &\n",
    "\\text{si } |\\bar{w}^k_j| \\leq \\lambda\\alpha. \\end{cases}\n",
    "\n",
    "En revanche cela ne permet pas d'avoir une bonne précision pour le minimum de F.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 6** Nous proposons la fonction\n",
    "\n",
    "$$\n",
    "F(w):=\\sum_{j=0}^{N-1} \\sin^2(w_j - w_{j-1}),\n",
    "$$\n",
    "où les indices $j$ sont compris modulo $N$.\n",
    "\n",
    "a) Justifiez la formule de $\\nabla F$ donnée dans la boîte suivante.\n",
    "\n",
    "b) Quels sont les minimiseurs de $F$ ?\n",
    "\n",
    "c) Quels sont les minimiseurs de $F_\\lambda$ pour $\\lambda>0$ ?\n",
    "\n",
    "d) Appliquez votre implémentation d'ISTA à l'optimisation de $F_\\lambda$. Dans le cas $\\lambda=0$, est-ce que les itérations convergent vers un minimiseur de $F$ ?\n",
    "\n",
    "e) Dans le cas $\\lambda>0$, est-ce que les itérations convergent vers un minimiseur de $F_\\lambda$ ? Sinon, pourquoi ?\n",
    "\n",
    "f) Les itérées convergent-elles vers un vecteur proche d'un minimiseur de $F$ ? Les solutions trouvées sont elles parcimonieuses ? Vos résultats numériques sont-ils cohérents avec (4) ? Justifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) $\\forall w, \\dfrac{\\partial F}{\\partial w_m} = \\sum_{j=0}^{N-1} 2(\\delta_{j,m}-\\delta_{j-1,m})\\cos( w_j - w_{j-1})\\sin( w_j - w_{j-1}) $\\\n",
    "$= 2 \\left[ \\cos( w_m - w_{m-1})\\sin(w_m - w_{m-1})-\\cos(w_{m+1} - w_{m})\\sin(w_{m-1} - w_{m})\\right] $\\\n",
    "$= \\sin(2(w_m - w_{m-1})) -\\sin(2(w_{m+1} - w_m)) $\\\n",
    "$= 2sin(2w_m-w_{m-1}-w_{m+1})cos(w_{m+1}-w_{m-1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) F est minimale si $w$  ses coefficients  égaux modulaux $2 \\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Si F est positive et son minimum est $w = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = lambda w : np.sum( np.sin(w - np.roll(w,1))**2 )\n",
    "GradF = lambda w : 2*np.sin(2*w - np.roll(w,1) - np.roll(w,-1))*np.cos(np.roll(w,1)                                                                   - np.roll(w,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Fv,E,NZ,W)=methodeISTA(Lambda=1.1,Nitermax=20)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(Fv)\n",
    "plt.title('Evolution de la fonction F')\n",
    "plt.xlabel(\"nombre d'itérations\")\n",
    "plt.ylabel(\"F(w)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 0px\">\n",
    "    \n",
    "   ___Solution 6.___ \n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Application à l'optimisation stochastique <a id='III'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercice 7.__\n",
    "\n",
    "\n",
    "a) Implémentez ISTA dans le cadre du problème de classification et de réseaux de neurones jouets définis ci-dessous. On prendra le taux d'apprentissage $\\alpha=5\\cdot10^{-2}$ et $\\lambda=10^{-3}$.\n",
    "\n",
    "Pour ce qui est de l'algorithme, les changements par rapport à ISTA sont :\n",
    "\n",
    "$\\qquad\\alpha$) dans la première étape de (12) on remplace $\\nabla F(A)$ par une moyenne des $\\nabla f_i(A)$ avec $i$ parcourant un mini-lot $I$ d'indices tirés au hasard.\n",
    "\n",
    "$\\qquad\\beta$) On utilise une stratégie de taux d'accroissements décroissants.\n",
    "\n",
    "Pour l'éude (graphique) de l'algorithme, on stockera l'erreur totale sur l'échantillon d'apprentissage ainsi que le nombre de composantes non nulles du paramètre $A$ au cours des époques.\n",
    "\n",
    "*Indications :*<br> \n",
    "$\\qquad\\qquad\\bullet$ La méthode _nn.count_non_zero(A)_ renvoie le nombre de composantes non nulles de la liste de coefficients _A_.<br> \n",
    "$\\qquad\\qquad\\bullet$ Combinée avec *np.where()*, la méthode *nn.maps()* est très pratique pour calculer les itérés de ISTA.<br>Si $f$ est une fonction qui prend en paramètres un tableau numpy _X_ et (éventuellement) un paramètre _p_ et renvoie un tableau de la même taille que _X_ alors, la méthode _nn.maps(f,A,param=p, output=False)_ remplace tous les coefficients $A_i$ de _A_ par *f(*$A_i$*,p)*.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "b) Observez les résultats numériques obtenus avec les paramètres proposés dans les deux boîtes suivantes. \n",
    "\n",
    "c) Essayez différentes valeurs pour $\\lambda$ et commentez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 0px\">\n",
    "\n",
    "___Solution 7.___ \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pb\n",
    "pb = ToyPb(name = \"ring\", bounds = (-1,1), loss=\"demanding\")\n",
    "\n",
    "# data\n",
    "ndata = 1000\n",
    "data = nD_data(n = ndata, pb = pb, init_pred=True)\n",
    "\n",
    "data.show_class()\n",
    "pb.show_border('k--')\n",
    "plt.legend(loc=1, fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# nn\n",
    "CardNodes = (2, 8, 8, 8, 1)\n",
    "nn= ToyNN(card = CardNodes, coef_bounds=(-1,1,-1,1),  chi=\"tanh\", grid=(-1,1,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution 5.i.a\n",
    "# Paramètres\n",
    "alpha0=0.05\n",
    "Nepoch=1000\n",
    "Nbatch=10\n",
    "Ndata=data.n\n",
    "nepochplot=50\n",
    "Niter_per_epoch=Ndata//Nbatch\n",
    "fact_dec_alpha=0 \n",
    "fact_dec_alpha=1/(600*Niter_per_epoch)\n",
    "\n",
    "\n",
    "nplot_per_row = 4 # nombre de figures par ligne\n",
    "\n",
    "# Initialisations\n",
    "A=nn.create_rand()\n",
    "nepoch=0\n",
    "k=0\n",
    "Erreur =[nn.total_loss(A,data,pb=pb)]\n",
    "plotpos=0\n",
    "NZ = [nn.count_non_zero(A)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda a,t : np.where(np.abs(a)<t,0,np.where(a>0,a-t,a+t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paramètres de l'algorithme\n",
    "# TEST AVEC LAMBDA = 10-3\n",
    "\n",
    "\n",
    "Lambda= 1e-3\n",
    "# Boucle d'optimisation pour la methode du gradient stochastique\n",
    "for i_ in range(Nepoch):\n",
    "    nepoch+=1\n",
    "    for j_ in range(Niter_per_epoch):\n",
    "        I = nprd.choice(Ndata, Nbatch)\n",
    "        DA=nn.create_zero()\n",
    "        for i in I:\n",
    "            x, y = data.X[i], data.Y[i]\n",
    "            nn.descent(A, x, y, alpha=1, B=DA, pb=pb)\n",
    "        nn.add(A, DA, c=alpha0/(Nbatch*(1+fact_dec_alpha*k)), output=False)\n",
    "        A=nn.maps(f,A,param = Lambda*alpha0/(Nbatch*(1+fact_dec_alpha*k)))\n",
    "        k +=1\n",
    "    \n",
    "    # calcul de l'erreur et représentations graphiques\n",
    "    if not nepoch%nepochplot:\n",
    "        error = nn.total_loss_and_prediction(A,data,pb=pb)\n",
    "        Erreur.append(error)\n",
    "        NZ.append(nn.count_non_zero(A))\n",
    "        if not plotpos: plt.figure(figsize=(16,4))\n",
    "        plotpos+=1\n",
    "        plt.subplot(1,nplot_per_row,plotpos)\n",
    "        data.show_class(pred=True)\n",
    "        nn.show_pred(A)\n",
    "        pb.show_border('k--')\n",
    "        plt.title(f\"ep: {nepoch}, Loss: {error:1.5e}.\", fontsize=12)\n",
    "        if plotpos==nplot_per_row :  plt.show(); plotpos=0\n",
    "    else:\n",
    "        error = nn.total_loss(A,data,pb=pb)\n",
    "        Erreur.append(error)\n",
    "        NZ.append(nn.count_non_zero(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Représentations graphiques de l'évolution de l'erreur et d au cours des époques.\n",
    "print(f\"Erreur initiale : {Erreur[0]:1.5e}\")\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "debut = 1\n",
    "plt.plot(np.linspace(debut, nepoch,nepoch-debut + 1),Erreur[debut:])\n",
    "plt.title(\"Erreur en fonction du nombre d'époques\")\n",
    "\n",
    "plt.subplot(122)\n",
    "debut = nepoch//2\n",
    "plt.plot(np.linspace(debut, nepoch,nepoch-debut + 1),Erreur[debut:])\n",
    "plt.title(\"Erreur en fonction du nombre d'époques\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "debut = 3*(nepoch//4)\n",
    "plt.plot(np.linspace(debut, nepoch,nepoch - debut + 1),Erreur[debut:])\n",
    "plt.title(\"Erreur en fonction du nombre d'époques\")\n",
    "\n",
    "plt.subplot(122)\n",
    "debut = 7*(nepoch//8)\n",
    "plt.plot(np.linspace(debut, nepoch,nepoch - debut + 1),Erreur[debut:])\n",
    "plt.title(\"Erreur en fonction du nombre d'époques\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(NZ)\n",
    "plt.title(\"Nombre de coefficients non nuls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paramètres de l'algorithme\n",
    "Lambda= 2e-2\n",
    "# Boucle d'optimisation pour la methode du gradient stochastique\n",
    "for i_ in range(Nepoch):\n",
    "    nepoch+=1\n",
    "    for j_ in range(Niter_per_epoch):\n",
    "        I = nprd.choice(Ndata, Nbatch)\n",
    "        DA=nn.create_zero()\n",
    "        for i in I:\n",
    "            x, y = data.X[i], data.Y[i]\n",
    "            nn.descent(A, x, y, alpha=1, B=DA, pb=pb)\n",
    "        nn.add(A, DA, c=alpha0/(Nbatch*(1+fact_dec_alpha*k)), output=False)\n",
    "        A=nn.maps(f,A,param = Lambda*alpha0/(Nbatch*(1+fact_dec_alpha*k)))\n",
    "        k +=1\n",
    "    \n",
    "    # calcul de l'erreur et représentations graphiques\n",
    "    if not nepoch%nepochplot:\n",
    "        error = nn.total_loss_and_prediction(A,data,pb=pb)\n",
    "        Erreur.append(error)\n",
    "        NZ.append(nn.count_non_zero(A))\n",
    "        if not plotpos: plt.figure(figsize=(16,4))\n",
    "        plotpos+=1\n",
    "        plt.subplot(1,nplot_per_row,plotpos)\n",
    "        data.show_class(pred=True)\n",
    "        nn.show_pred(A)\n",
    "        pb.show_border('k--')\n",
    "        plt.title(f\"ep: {nepoch}, Loss: {error:1.5e}.\", fontsize=12)\n",
    "        if plotpos==nplot_per_row :  plt.show(); plotpos=0\n",
    "    else:\n",
    "        error = nn.total_loss(A,data,pb=pb)\n",
    "        Erreur.append(error)\n",
    "        NZ.append(nn.count_non_zero(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Représentations graphiques de l'évolution de l'erreur et d au cours des époques.\n",
    "print(f\"Erreur initiale : {Erreur[0]:1.5e}\")\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "debut = 1\n",
    "plt.plot(np.linspace(debut, nepoch,nepoch-debut + 1),Erreur[debut:])\n",
    "plt.title(\"Erreur en fonction du nombre d'époques\")\n",
    "\n",
    "plt.subplot(122)\n",
    "debut = nepoch//2\n",
    "plt.plot(np.linspace(debut, nepoch,nepoch-debut + 1),Erreur[debut:])\n",
    "plt.title(\"Erreur en fonction du nombre d'époques\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(121)\n",
    "debut = 3*(nepoch//4)\n",
    "plt.plot(np.linspace(debut, nepoch,nepoch - debut + 1),Erreur[debut:])\n",
    "plt.title(\"Erreur en fonction du nombre d'époques\")\n",
    "\n",
    "plt.subplot(122)\n",
    "debut = 7*(nepoch//8)\n",
    "plt.plot(np.linspace(debut, nepoch,nepoch - debut + 1),Erreur[debut:])\n",
    "plt.title(\"Erreur en fonction du nombre d'époques\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(NZ)\n",
    "plt.title(\"Nombre de coefficients non nuls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que quand $\\lambda = 10^{-3}$, le nombre de coefficients non nuls reste à 177. La régularisation n'est pas assez forte tandis que pour $\\lambda = 2.10^{-2}$, le nombre de coefficients non nuls converge approximativement vers à 70. La régularisation fait bien tendre les coefficients vers 0. \\\\\n",
    "\n",
    "Au bout de 1000 itérations, on observe néanmoins un meilleur résultat pour $\\lambda = 10^{-3}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bot'></a>\n",
    "<a href=\"#toc\">top</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I\">I.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I1\">I.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I2\">I.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#I3\">I.3</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II\">II.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II1\">II.1</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#II2\">II.2</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#III\">III.</a>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<a href=\"#bot\">bot.</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "GafO0zXoJ6Cx",
    "5l_mvC1OJ6Da",
    "ZzS5-IzwaKn3",
    "89AjhkJ2aKoB"
   ],
   "name": "ToyNN_class.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fc181ad2d5a8668b9dc9dc9be5fdfb576ae548dec1bb9e3b7af6d356f2704ac2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
